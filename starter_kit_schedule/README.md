# Curriculum Learning Pipeline for VBot Navigation

Multi-stage curriculum training system for the MotrixArena S1 quadruped navigation competition.

## âš¡ Quick Start

```powershell
# 1. Initialize curriculum campaign
uv run python starter_kit_schedule/scripts/init_campaign.py `
    --name "VBot Stage1 Curriculum" `
    --template curriculum_plan_template.yaml

# 2. Start training
uv run python starter_kit_schedule/scripts/run_search.py

# 3. Monitor progress
uv run python starter_kit_schedule/scripts/status.py --watch

# 4. Analyze results
uv run python starter_kit_schedule/scripts/analyze.py --top 5
```

## ğŸ“‹ Curriculum Stages

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CURRICULUM PROGRESSION                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                               â”‚
â”‚  STAGE 1: Flat Ground    â”€â”€â”€â”€â”€â–º  STAGE 2A: Waves    â”€â”€â”€â”€â”€â–º  STAGE 2B: Stairs â”‚
â”‚  â””â”€ Basic locomotion            â””â”€ Terrain adapt           â””â”€ Climbing        â”‚
â”‚  â””â”€ Goal navigation             â””â”€ Height variance         â””â”€ Foot clearance  â”‚
â”‚  â””â”€ 50M steps                   â””â”€ 30M steps               â””â”€ 40M steps       â”‚
â”‚                                                                               â”‚
â”‚                              STAGE 2C: Obstacles  â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                              â””â”€ Ball avoidance                                â”‚
â”‚                              â””â”€ 30M steps                                     â”‚
â”‚                                    â”‚                                          â”‚
â”‚                                    â–¼                                          â”‚
â”‚                              FINAL: Full Course                               â”‚
â”‚                              â””â”€ All terrain types                             â”‚
â”‚                              â””â”€ 50M steps                                     â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Reward Engineering

### Key Rewards Table

| Component | Weight | Stage | Description |
|-----------|--------|-------|-------------|
| `position_tracking` | 2.0 | All | Primary goal-seeking |
| `fine_position_tracking` | 2.0 | All | Dense reward when close |
| `heading_tracking` | 1.0 | All | Face direction of travel |
| `orientation` | -0.05 | All | Penalize body tilt |
| `lin_vel_z` | -0.5 | All | Penalize bouncing |
| `termination` | -200 | All | Body collision |
| `knee_lift_bonus` | 0.2 | Stairs | Leg clearance |
| `ball_collision` | -5.0 | Obstacles | Dynamic obstacle |

### Tuning Tips

- **Robot doesn't move**: Increase `position_tracking` weight (2.0 â†’ 3.0)
- **Robot falls often**: Increase `orientation` penalty (-0.05 â†’ -0.1)
- **Robot bounces**: Increase `lin_vel_z` penalty (-0.5 â†’ -1.0)
- **Robot is jerky**: Increase `action_rate` penalty (-0.01 â†’ -0.02)
- **Reward is too sparse**: Add checkpoint bonuses along path

## ğŸ“ Directory Structure

```
starter_kit_schedule/
â”œâ”€â”€ plans/                     # Curriculum plan definitions
â”‚   â”œâ”€â”€ active_plan.yaml       # Current active training plan
â”‚   â””â”€â”€ archive/               # Completed plans
â”‚
â”œâ”€â”€ configs/                   # Hyperparameter configurations
â”‚   â””â”€â”€ generated/             # Auto-generated configs from search
â”‚
â”œâ”€â”€ progress/                  # Execution tracking
â”‚   â”œâ”€â”€ current_run.yaml       # Currently running experiment
â”‚   â”œâ”€â”€ queue.yaml             # Pending experiments
â”‚   â””â”€â”€ completed.yaml         # Finished experiments
â”‚
â”œâ”€â”€ checkpoints/               # Checkpoint registry for warm-starts
â”‚
â”œâ”€â”€ scripts/                   # Pipeline scripts
â”‚   â”œâ”€â”€ init_campaign.py       # Initialize new curriculum campaign
â”‚   â”œâ”€â”€ run_search.py          # Execute training runs
â”‚   â”œâ”€â”€ status.py              # Monitor progress
â”‚   â””â”€â”€ analyze.py             # Analyze and compare results
â”‚
â””â”€â”€ templates/                 # Configuration templates
    â”œâ”€â”€ curriculum_plan_template.yaml   # Multi-stage curriculum
    â”œâ”€â”€ reward_config_template.yaml     # Reward engineering config
    â”œâ”€â”€ search_space_template.yaml      # Hyperparameter search space
    â””â”€â”€ config_template.yaml            # Basic config template

starter_kit_log/
â”œâ”€â”€ experiments/               # Individual experiment logs
â”‚   â””â”€â”€ EXP_YYYYMMDD_HHMMSS/   # Per-experiment data
â”œâ”€â”€ campaigns/                 # Campaign-level summaries
â”‚   â””â”€â”€ campaign_YYYYMMDD/     # Per-campaign data
â””â”€â”€ analysis/                  # Comparison reports
    â”œâ”€â”€ rankings/              # Sorted by metrics
    â”œâ”€â”€ hyperparameter_importance/
    â””â”€â”€ visualizations/
```

## âš™ï¸ Templates

### `curriculum_plan_template.yaml`
Multi-stage curriculum with stage-specific reward overrides and promotion criteria.

### `reward_config_template.yaml`
Comprehensive reward engineering configuration with all components documented.

### `search_space_template.yaml`
Hyperparameter search space focused on reward weights and PPO dynamics.

## ğŸ” Search Presets

| Preset | Trials | Focus | Use When |
|--------|--------|-------|----------|
| `quick_test` | 10 | Key params only | Sanity check |
| `reward_focus` | 50 | Reward weights | Tuning reward balance |
| `ppo_focus` | 50 | PPO params | Tuning learning dynamics |
| `full_search` | 200 | Everything | Final optimization |

## ğŸ“Š Monitoring Commands

```powershell
# Watch training progress in real-time
uv run python starter_kit_schedule/scripts/status.py --watch

# Check specific campaign
uv run python starter_kit_schedule/scripts/status.py --campaign campaign_20250101

# Show top 5 experiments by reward
uv run python starter_kit_schedule/scripts/analyze.py --top 5 --sort reward

# Export best config for deployment
uv run python starter_kit_schedule/scripts/analyze.py --export-best configs/best.yaml
```

## ğŸ”— Integration with subagent-copilot-cli

For image analysis and training curve visualization:

```powershell
# Analyze reward curve screenshot
gh copilot explain "Analyze reward curve at starter_kit_log/experiments/EXP_001/reward_curve.png"

# Compare simulation frames
gh copilot explain "Compare robot behavior at frame_100.png vs frame_500.png"
```

## ğŸ“ Notes

- Always start with Stage 1 flat ground training
- Use warm-start with reduced LR (0.5Ã—) when advancing stages
- Monitor termination rate - should decrease as training progresses
- Save checkpoints frequently (every 500 updates recommended)
- Back up best checkpoints before advancing to next stage
