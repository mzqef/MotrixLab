{
  "run_tag": "v35_kl_adaptive_best",
  "env_name": "vbot_navigation_section011",
  "starter_kit_dir": "D:\\MotrixLab\\starter_kit\\navigation2",
  "best_checkpoint": {
    "run": "26-02-17_20-42-31-320016_PPO",
    "file": "agent_6000.pt",
    "metric_wp_idx": 5.9115,
    "schedule_path": "starter_kit_schedule/checkpoints/vbot_navigation_section011/best_agent.pt"
  },
  "description": "v35: KL-adaptive LR scheduler + warm-start from agent_5000.pt (pre-peak, ascending slope). NEW ALL-TIME BEST wp_idx=5.9115. Key insight: warm-starting from pre-peak checkpoint (5000) instead of peak (6000) gives optimizer a clear uphill gradient. KL-adaptive scheduler prevents catastrophic forgetting (v29 degraded from 5.86→2.85, v35 degrades 5.91→3.51 but slower).",
  "supersedes": "v29_best_wpidx586.json",
  "reward_scales": {
    "forward_velocity": 2.875,
    "waypoint_approach": 166.5,
    "waypoint_facing": 0.061,
    "position_tracking": 0.384,
    "alive_bonus": 1.446,
    "waypoint_bonus": 50.0,
    "smiley_bonus": 20.0,
    "red_packet_bonus": 20.0,
    "phase_completion_bonus": 25.0,
    "zone_approach": 35.06,
    "height_progress": 28.30,
    "height_approach": 5.0,
    "height_oscillation": -2.0,
    "traversal_bonus": 0.0,
    "foot_clearance": 0.053,
    "foot_clearance_bump_boost": 4.39,
    "jump_reward": 10.0,
    "per_jump_bonus": 25.0,
    "celebration_bonus": 80.0,
    "stance_ratio": 0.041,
    "vel_heading_alignment": 0.0,
    "heading_command_shaping": 0.0,
    "swing_contact_penalty": -0.031,
    "swing_contact_bump_scale": 0.356,
    "impact_penalty": -0.080,
    "torque_saturation": -0.025,
    "orientation": -0.027,
    "slope_orientation": 0.0,
    "lin_vel_z": -0.195,
    "ang_vel_xy": -0.045,
    "torques": -5e-6,
    "dof_vel": -3e-5,
    "dof_acc": -1.5e-7,
    "action_rate": -0.008,
    "termination": -200.0
  },
  "rl_overrides": {
    "learning_rate": 1.0e-4,
    "lr_scheduler_type": "kl_adaptive",
    "entropy_loss_scale": 4.11e-3,
    "policy_hidden_layer_sizes": [256, 128, 64],
    "value_hidden_layer_sizes": [512, 256, 128],
    "rollouts": 24,
    "learning_epochs": 6,
    "mini_batches": 16,
    "discount_factor": 0.999,
    "lambda_param": 0.99,
    "max_env_steps": 50000000,
    "seed": 42,
    "check_point_interval": 500,
    "num_envs": 2048,
    "grad_norm_clip": 1.0,
    "ratio_clip": 0.2,
    "value_clip": 0.2
  },
  "env_overrides": {
    "action_scale": 0.6,
    "max_episode_seconds": 60.0,
    "max_episode_steps": 6000,
    "grace_period_steps": 100,
    "celebration_jump_threshold": 1.55,
    "required_jumps": 3,
    "celebration_landing_z": 1.50
  },
  "training_history": {
    "warm_start_source": "26-02-17_10-45-19-130319_PPO/checkpoints/agent_5000.pt (v29 pre-peak, wp_idx=5.41)",
    "warm_start_chain": [
      "Stage 15 (gamma/lambda optimized, wp_idx=1.977)",
      "-> v23b-T7 AutoML winner (gradient-only)",
      "-> v25 ordered targeting",
      "-> v27 multi-jump celebration",
      "-> v28 re-enabled bonuses (wp_idx=5.05)",
      "-> v29 boosted later-phase bonuses (wp_idx=5.86)",
      "-> v35 KL-adaptive + pre-peak warm-start (wp_idx=5.91 NEW BEST)"
    ],
    "key_discoveries": [
      "KL-adaptive scheduler: auto-reduces LR based on policy divergence, prevents catastrophic forgetting",
      "Pre-peak warm-start: loading agent_5000 (ascending slope) > agent_6000 (peak) for optimizer recovery",
      "Optimizer state reset is the root cause of warm-start degradation (SKRL loads weights only, not Adam state)",
      "Performance consistently peaks at step ~6000 regardless of config — the effective training window is narrow",
      "v30 (reward change) < v31 (LR-only) < v32 (kl_adaptive from peak) < v35 (kl_adaptive from pre-peak)"
    ],
    "experiments_this_session": {
      "v30": {"change": "torque_saturation -0.025 -> -0.010", "peak_wp_idx": 4.02, "verdict": "WORSE — reward shift disrupted value function"},
      "v31": {"change": "LR 1e-4 -> 5e-5 only", "peak_wp_idx": 1.68, "verdict": "WORSE — too slow recovery from optimizer reset"},
      "v32": {"change": "kl_adaptive + LR=1e-4 from agent_6000", "peak_wp_idx": 5.49, "verdict": "GOOD — better stability, slightly below v29 peak"},
      "v33": {"change": "kl_adaptive + LR=2e-4 from agent_6000", "peak_wp_idx": 4.63, "verdict": "SAME as v32 — KL scheduler normalizes effective LR"},
      "v34": {"change": "no scheduler + LR=1e-4 + ckpt_interval=250 from agent_6000", "peak_wp_idx": 3.22, "verdict": "WORSE — confirms kl_adaptive is essential"},
      "v35": {"change": "kl_adaptive + LR=1e-4 from agent_5000 (pre-peak)", "peak_wp_idx": 5.9115, "verdict": "NEW BEST — pre-peak warm-start + KL-adaptive"}
    }
  }
}
